%%% Abstract.tex --- 
%% 
%% Filename: Abstract.tex
%% Description: 
%% Author: Ola Leifler
%% Maintainer: 
%% Created: Thu Oct 14 13:34:11 2010 (CEST)
%% Version: $Id$
%% Version: 
%% Last-Updated: Tue Dec  1 15:19:52 2015 (+0100)
%%           By: Ola Leifler
%%     Update #: 4
%% URL: 
%% Keywords: 
%% Compatibility: 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Commentary: 
%% 
%% 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Change log:
%% 
%% 
%% RCS $Log$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Code:
The use of neural networks is more and more explored in natural language processing. Very recently, researchers applied neural networks to dependency parsing; however, existing parsers based on neural networks have complicated architectures. This thesis implements a graph-based dependency parser with a simple feedforward neural network model. Dependency parsing is cast as a structured prediction problem within the framework of statistical learning. We present the feedforward neural network as a generative model. Our neural network model is trained by minimizing the upper bound of posterior expected loss on a training set, which is equivalent to the so called max-margin principle. Experimental results show that the performance of our parser is close to that of existing parsers based on neural networks, despite a considerably simpler architecture.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract.tex ends here


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "demothesis"
%%% End: 
